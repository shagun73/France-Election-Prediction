{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "list_files=[\"database_11_1.sqlite\",\"database_12_0.sqlite\",\"database_12_1.sqlite\",\"database_13_0.sqlite\",\"database_13_1.sqlite\",\"database_14_0.sqlite\",\"database_15_0.sqlite\",\"database_15_1.sqlite\",\"database_16_0.sqlite\",\"database_16_1.sqlite\",\"database_17_0.sqlite\",\"database_14_1.sqlite\"]\n",
    "\n",
    "list_df=[]\n",
    "for file in list_files:\n",
    "    print(file)\n",
    "    connection = sqlite3.connect(format(file))\n",
    "    df_tweet= pd.read_sql_query(\"SELECT * from data\", connection)\n",
    "    connection.close()\n",
    "    #Filter the data \n",
    "    #df_tweet=df_tweet.loc[df_tweet['lang']==\"fr\"]\n",
    "    list_df.append(df_tweet)\n",
    "\n",
    "df_tweets=pd.concat(list_df,axis=0)\n",
    "print(df_tweets.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math, re, string, requests, json\n",
    "from itertools import product\n",
    "from inspect import getsourcefile\n",
    "from os.path import abspath, join, dirname\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "#Data analytics libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Data management libraries\n",
    "import sqlite3\n",
    "from textblob import Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "import codecs\n",
    "import sys  \n",
    "\n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "#Data management libraries\n",
    "import sqlite3\n",
    "\n",
    "##Constants##\n",
    "\n",
    "# (empirically derived mean sentiment intensity rating increase for booster words)\n",
    "B_INCR = 0.293\n",
    "B_DECR = -0.293\n",
    "\n",
    "# (empirically derived mean sentiment intensity rating increase for using\n",
    "# ALLCAPs to emphasize a word)\n",
    "C_INCR = 0.733\n",
    "\n",
    "N_SCALAR = -0.74\n",
    "\n",
    "# for removing punctuation\n",
    "REGEX_REMOVE_PUNCTUATION = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "PUNC_LIST = [\".\", \"!\", \"?\", \",\", \";\", \":\", \"-\", \"'\", \"\\\"\",\n",
    "             \"!!\", \"!!!\", \"??\", \"???\", \"?!?\", \"!?!\", \"?!?!\", \"!?!?\"]\n",
    "NEGATE = \\\n",
    "[\"aint\", \"arent\", \"cannot\", \"cant\", \"couldnt\", \"darent\", \"didnt\", \"doesnt\",\n",
    " \"ain't\", \"aren't\", \"can't\", \"couldn't\", \"daren't\", \"didn't\", \"doesn't\",\n",
    " \"dont\", \"hadnt\", \"hasnt\", \"havent\", \"isnt\", \"mightnt\", \"mustnt\", \"neither\",\n",
    " \"don't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\", \"mustn't\",\n",
    " \"neednt\", \"needn't\", \"never\", \"none\", \"nope\", \"nor\", \"not\", \"nothing\", \"nowhere\",\n",
    " \"oughtnt\", \"shant\", \"shouldnt\", \"uhuh\", \"wasnt\", \"werent\",\n",
    " \"oughtn't\", \"shan't\", \"shouldn't\", \"uh-uh\", \"wasn't\", \"weren't\",\n",
    " \"without\", \"wont\", \"wouldnt\", \"won't\", \"wouldn't\", \"rarely\", \"seldom\", \"despite\"]\n",
    "\n",
    "# booster/dampener 'intensifiers' or 'degree adverbs'\n",
    "# http://en.wiktionary.org/wiki/Category:English_degree_adverbs\n",
    "\n",
    "BOOSTER_DICT = \\\n",
    "{\"absolutely\": B_INCR, \"amazingly\": B_INCR, \"awfully\": B_INCR, \"completely\": B_INCR, \"considerably\": B_INCR,\n",
    " \"decidedly\": B_INCR, \"deeply\": B_INCR, \"effing\": B_INCR, \"enormously\": B_INCR,\n",
    " \"entirely\": B_INCR, \"especially\": B_INCR, \"exceptionally\": B_INCR, \"extremely\": B_INCR,\n",
    " \"fabulously\": B_INCR, \"flipping\": B_INCR, \"flippin\": B_INCR,\n",
    " \"fricking\": B_INCR, \"frickin\": B_INCR, \"frigging\": B_INCR, \"friggin\": B_INCR, \"fully\": B_INCR, \"fucking\": B_INCR,\n",
    " \"greatly\": B_INCR, \"hella\": B_INCR, \"highly\": B_INCR, \"hugely\": B_INCR, \"incredibly\": B_INCR,\n",
    " \"intensely\": B_INCR, \"majorly\": B_INCR, \"more\": B_INCR, \"most\": B_INCR, \"particularly\": B_INCR,\n",
    " \"purely\": B_INCR, \"quite\": B_INCR, \"really\": B_INCR, \"remarkably\": B_INCR,\n",
    " \"so\": B_INCR, \"substantially\": B_INCR,\n",
    " \"thoroughly\": B_INCR, \"totally\": B_INCR, \"tremendously\": B_INCR,\n",
    " \"uber\": B_INCR, \"unbelievably\": B_INCR, \"unusually\": B_INCR, \"utterly\": B_INCR,\n",
    " \"very\": B_INCR,\n",
    " \"almost\": B_DECR, \"barely\": B_DECR, \"hardly\": B_DECR, \"just enough\": B_DECR,\n",
    " \"kind of\": B_DECR, \"kinda\": B_DECR, \"kindof\": B_DECR, \"kind-of\": B_DECR,\n",
    " \"less\": B_DECR, \"little\": B_DECR, \"marginally\": B_DECR, \"occasionally\": B_DECR, \"partly\": B_DECR,\n",
    " \"scarcely\": B_DECR, \"slightly\": B_DECR, \"somewhat\": B_DECR,\n",
    " \"sort of\": B_DECR, \"sorta\": B_DECR, \"sortof\": B_DECR, \"sort-of\": B_DECR}\n",
    "\n",
    "# check for special case idioms using a sentiment-laden keyword known to VADER\n",
    "SPECIAL_CASE_IDIOMS = {\"the shit\": 3, \"the bomb\": 3, \"bad ass\": 1.5, \"yeah right\": -2,\n",
    "                       \"cut the mustard\": 2, \"kiss of death\": -1.5, \"hand to mouth\": -2}\n",
    "\n",
    "\n",
    "##Static methods##\n",
    "\n",
    "def negated(input_words, include_nt=True):\n",
    "    \"\"\"\n",
    "    Determine if input contains negation words\n",
    "    \"\"\"\n",
    "    neg_words = []\n",
    "    neg_words.extend(NEGATE)\n",
    "    for word in neg_words:\n",
    "        if word in input_words:\n",
    "            return True\n",
    "    if include_nt:\n",
    "        for word in input_words:\n",
    "            if \"n't\" in word:\n",
    "                return True\n",
    "    if \"least\" in input_words:\n",
    "        i = input_words.index(\"least\")\n",
    "        if i > 0 and input_words[i-1] != \"at\":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def normalize(score, alpha=15):\n",
    "    \"\"\"\n",
    "    Normalize the score to be between -1 and 1 using an alpha that\n",
    "    approximates the max expected value\n",
    "    \"\"\"\n",
    "    norm_score = score/math.sqrt((score*score) + alpha)\n",
    "    if norm_score < -1.0: \n",
    "        return -1.0\n",
    "    elif norm_score > 1.0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return norm_score\n",
    "\n",
    "\n",
    "def allcap_differential(words):\n",
    "    \"\"\"\n",
    "    Check whether just some words in the input are ALL CAPS\n",
    "    :param list words: The words to inspect\n",
    "    :returns: `True` if some but not all items in `words` are ALL CAPS\n",
    "    \"\"\"\n",
    "    is_different = False\n",
    "    allcap_words = 0\n",
    "    for word in words:\n",
    "        if word.isupper():\n",
    "            allcap_words += 1\n",
    "    cap_differential = len(words) - allcap_words\n",
    "    if cap_differential > 0 and cap_differential < len(words):\n",
    "        is_different = True\n",
    "    return is_different\n",
    "\n",
    "\n",
    "def scalar_inc_dec(word, valence, is_cap_diff):\n",
    "    \"\"\"\n",
    "    Check if the preceding words increase, decrease, or negate/nullify the\n",
    "    valence\n",
    "    \"\"\"\n",
    "    scalar = 0.0\n",
    "    word_lower = word.lower()\n",
    "    if word_lower in BOOSTER_DICT:\n",
    "        scalar = BOOSTER_DICT[word_lower]\n",
    "        if valence < 0:\n",
    "            scalar *= -1\n",
    "        #check if booster/dampener word is in ALLCAPS (while others aren't)\n",
    "        if word.isupper() and is_cap_diff:\n",
    "            if valence > 0:\n",
    "                scalar += C_INCR\n",
    "            else: scalar -= C_INCR\n",
    "    return scalar\n",
    "\n",
    "class SentiText(object):\n",
    "    \"\"\"\n",
    "    Identify sentiment-relevant string-level properties of input text.\n",
    "    \"\"\"\n",
    "    def __init__(self, text):\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text.encode('utf-8'))\n",
    "        self.text = text\n",
    "        self.words_and_emoticons = self._words_and_emoticons()\n",
    "        # doesn't separate words from\\\n",
    "        # adjacent punctuation (keeps emoticons & contractions)\n",
    "        self.is_cap_diff = allcap_differential(self.words_and_emoticons)\n",
    "\n",
    "    def _words_plus_punc(self):\n",
    "        \"\"\"\n",
    "        Returns mapping of form:\n",
    "        {\n",
    "            'cat,': 'cat',\n",
    "            ',cat': 'cat',\n",
    "        }\n",
    "        \"\"\"\n",
    "        no_punc_text = REGEX_REMOVE_PUNCTUATION.sub('', self.text)\n",
    "        # removes punctuation (but loses emoticons & contractions)\n",
    "        words_only = no_punc_text.split()\n",
    "        # remove singletons\n",
    "        words_only = set( w for w in words_only if len(w) > 1 )\n",
    "        # the product gives ('cat', ',') and (',', 'cat')\n",
    "        punc_before = {''.join(p): p[1] for p in product(PUNC_LIST, words_only)}\n",
    "        punc_after = {''.join(p): p[0] for p in product(words_only, PUNC_LIST)}\n",
    "        words_punc_dict = punc_before\n",
    "        words_punc_dict.update(punc_after)\n",
    "        return words_punc_dict\n",
    "\n",
    "    def _words_and_emoticons(self):\n",
    "        \"\"\"\n",
    "        Removes leading and trailing puncutation\n",
    "        Leaves contractions and most emoticons\n",
    "            Does not preserve punc-plus-letter emoticons (e.g. :D)\n",
    "        \"\"\"\n",
    "        wes = self.text.split()\n",
    "        words_punc_dict = self._words_plus_punc()\n",
    "        wes = [we for we in wes if len(we) > 1]\n",
    "        for i, we in enumerate(wes):\n",
    "            if we in words_punc_dict:\n",
    "                wes[i] = words_punc_dict[we]\n",
    "        return wes\n",
    "\n",
    "class SentimentIntensityAnalyzer(object):\n",
    "    \"\"\"\n",
    "    Give a sentiment intensity score to sentences.\n",
    "    \"\"\"\n",
    "    def __init__(self, lexicon_file=\"vader_lexicon.txt\"):\n",
    "        _this_module_file_path_ = abspath(getsourcefile(lambda:0))\n",
    "        lexicon_full_filepath = join(dirname(_this_module_file_path_), lexicon_file)\n",
    "        with open(lexicon_full_filepath) as f:\n",
    "            self.lexicon_full_filepath = f.read()\n",
    "        self.lexicon = self.make_lex_dict()\n",
    "\n",
    "    def make_lex_dict(self):\n",
    "        \"\"\"\n",
    "        Convert lexicon file to a dictionary\n",
    "        \"\"\"\n",
    "        lex_dict = {}\n",
    "        for line in self.lexicon_full_filepath.split('\\n'):\n",
    "            (word, measure) = line.strip().split('\\t')[0:2]\n",
    "            lex_dict[word] = float(measure)\n",
    "        return lex_dict\n",
    "\n",
    "    def polarity_scores(self, text):\n",
    "        \"\"\"\n",
    "        Return a float for sentiment strength based on the input text.\n",
    "        Positive values are positive valence, negative value are negative\n",
    "        valence.\n",
    "        \"\"\"\n",
    "        sentitext = SentiText(text)\n",
    "        #text, words_and_emoticons, is_cap_diff = self.preprocess(text)\n",
    "\n",
    "        sentiments = []\n",
    "        words_and_emoticons = sentitext.words_and_emoticons\n",
    "        for item in words_and_emoticons:\n",
    "            valence = 0\n",
    "            i = words_and_emoticons.index(item)\n",
    "            if (i < len(words_and_emoticons) - 1 and item.lower() == \"kind\" and \\\n",
    "                words_and_emoticons[i+1].lower() == \"of\") or \\\n",
    "                item.lower() in BOOSTER_DICT:\n",
    "                sentiments.append(valence)\n",
    "                continue\n",
    "\n",
    "            sentiments = self.sentiment_valence(valence, sentitext, item, i, sentiments)\n",
    "\n",
    "        sentiments = self._but_check(words_and_emoticons, sentiments)\n",
    "        \n",
    "        valence_dict = self.score_valence(sentiments, text)\n",
    "\n",
    "        return valence_dict\n",
    "\n",
    "    def sentiment_valence(self, valence, sentitext, item, i, sentiments):\n",
    "        is_cap_diff = sentitext.is_cap_diff\n",
    "        words_and_emoticons = sentitext.words_and_emoticons\n",
    "        item_lowercase = item.lower()\n",
    "        if item_lowercase in self.lexicon:\n",
    "            #get the sentiment valence\n",
    "            valence = self.lexicon[item_lowercase]\n",
    "\n",
    "            #check if sentiment laden word is in ALL CAPS (while others aren't)\n",
    "            if item.isupper() and is_cap_diff:\n",
    "                if valence > 0:\n",
    "                    valence += C_INCR\n",
    "                else:\n",
    "                    valence -= C_INCR\n",
    "\n",
    "            for start_i in range(0,3):\n",
    "                if i > start_i and words_and_emoticons[i-(start_i+1)].lower() not in self.lexicon:\n",
    "                    # dampen the scalar modifier of preceding words and emoticons\n",
    "                    # (excluding the ones that immediately preceed the item) based\n",
    "                    # on their distance from the current item.\n",
    "                    s = scalar_inc_dec(words_and_emoticons[i-(start_i+1)], valence, is_cap_diff)\n",
    "                    if start_i == 1 and s != 0:\n",
    "                        s = s*0.95\n",
    "                    if start_i == 2 and s != 0:\n",
    "                        s = s*0.9\n",
    "                    valence = valence+s\n",
    "                    valence = self._never_check(valence, words_and_emoticons, start_i, i)\n",
    "                    if start_i == 2:\n",
    "                        valence = self._idioms_check(valence, words_and_emoticons, i)\n",
    "\n",
    "                        # future work: consider other sentiment-laden idioms\n",
    "                        # other_idioms =\n",
    "                        # {\"back handed\": -2, \"blow smoke\": -2, \"blowing smoke\": -2,\n",
    "                        #  \"upper hand\": 1, \"break a leg\": 2,\n",
    "                        #  \"cooking with gas\": 2, \"in the black\": 2, \"in the red\": -2,\n",
    "                        #  \"on the ball\": 2,\"under the weather\": -2}\n",
    "\n",
    "            valence = self._least_check(valence, words_and_emoticons, i)\n",
    "\n",
    "        sentiments.append(valence)\n",
    "        return sentiments\n",
    "\n",
    "    def _least_check(self, valence, words_and_emoticons, i):\n",
    "        # check for negation case using \"least\"\n",
    "        if i > 1 and words_and_emoticons[i-1].lower() not in self.lexicon \\\n",
    "           and words_and_emoticons[i-1].lower() == \"least\":\n",
    "            if words_and_emoticons[i-2].lower() != \"at\" and words_and_emoticons[i-2].lower() != \"very\":\n",
    "                valence = valence*N_SCALAR\n",
    "        elif i > 0 and words_and_emoticons[i-1].lower() not in self.lexicon \\\n",
    "             and words_and_emoticons[i-1].lower() == \"least\":\n",
    "            valence = valence*N_SCALAR\n",
    "        return valence\n",
    "\n",
    "    def _but_check(self, words_and_emoticons, sentiments):\n",
    "        # check for modification in sentiment due to contrastive conjunction 'but'\n",
    "        if 'but' in words_and_emoticons or 'BUT' in words_and_emoticons:\n",
    "            try:\n",
    "                bi = words_and_emoticons.index('but')\n",
    "            except ValueError:\n",
    "                bi = words_and_emoticons.index('BUT')\n",
    "            for sentiment in sentiments:\n",
    "                si = sentiments.index(sentiment)\n",
    "                if si < bi:\n",
    "                    sentiments.pop(si)\n",
    "                    sentiments.insert(si, sentiment*0.5)\n",
    "                elif si > bi:\n",
    "                    sentiments.pop(si)\n",
    "                    sentiments.insert(si, sentiment*1.5)\n",
    "        return sentiments\n",
    "\n",
    "    def _idioms_check(self, valence, words_and_emoticons, i):\n",
    "        onezero = \"{0} {1}\".format(words_and_emoticons[i-1], words_and_emoticons[i])\n",
    "\n",
    "        twoonezero = \"{0} {1} {2}\".format(words_and_emoticons[i-2],\n",
    "                                       words_and_emoticons[i-1], words_and_emoticons[i])\n",
    "\n",
    "        twoone = \"{0} {1}\".format(words_and_emoticons[i-2], words_and_emoticons[i-1])\n",
    "\n",
    "        threetwoone = \"{0} {1} {2}\".format(words_and_emoticons[i-3],\n",
    "                                        words_and_emoticons[i-2], words_and_emoticons[i-1])\n",
    "\n",
    "        threetwo = \"{0} {1}\".format(words_and_emoticons[i-3], words_and_emoticons[i-2])\n",
    "\n",
    "        sequences = [onezero, twoonezero, twoone, threetwoone, threetwo]\n",
    "\n",
    "        for seq in sequences:\n",
    "            if seq in SPECIAL_CASE_IDIOMS:\n",
    "                valence = SPECIAL_CASE_IDIOMS[seq]\n",
    "                break\n",
    "\n",
    "        if len(words_and_emoticons)-1 > i:\n",
    "            zeroone = \"{0} {1}\".format(words_and_emoticons[i], words_and_emoticons[i+1])\n",
    "            if zeroone in SPECIAL_CASE_IDIOMS:\n",
    "                valence = SPECIAL_CASE_IDIOMS[zeroone]\n",
    "        if len(words_and_emoticons)-1 > i+1:\n",
    "            zeroonetwo = \"{0} {1} {2}\".format(words_and_emoticons[i], words_and_emoticons[i+1], words_and_emoticons[i+2])\n",
    "            if zeroonetwo in SPECIAL_CASE_IDIOMS:\n",
    "                valence = SPECIAL_CASE_IDIOMS[zeroonetwo]\n",
    "\n",
    "        # check for booster/dampener bi-grams such as 'sort of' or 'kind of'\n",
    "        if threetwo in BOOSTER_DICT or twoone in BOOSTER_DICT:\n",
    "            valence = valence+B_DECR\n",
    "        return valence\n",
    "\n",
    "    def _never_check(self, valence, words_and_emoticons, start_i, i):\n",
    "        if start_i == 0:\n",
    "            if negated([words_and_emoticons[i-1]]):\n",
    "                    valence = valence*N_SCALAR\n",
    "        if start_i == 1:\n",
    "            if words_and_emoticons[i-2] == \"never\" and\\\n",
    "               (words_and_emoticons[i-1] == \"so\" or\n",
    "                words_and_emoticons[i-1] == \"this\"):\n",
    "                valence = valence*1.5\n",
    "            elif negated([words_and_emoticons[i-(start_i+1)]]):\n",
    "                valence = valence*N_SCALAR\n",
    "        if start_i == 2:\n",
    "            if words_and_emoticons[i-3] == \"never\" and \\\n",
    "               (words_and_emoticons[i-2] == \"so\" or words_and_emoticons[i-2] == \"this\") or \\\n",
    "               (words_and_emoticons[i-1] == \"so\" or words_and_emoticons[i-1] == \"this\"):\n",
    "                valence = valence*1.25\n",
    "            elif negated([words_and_emoticons[i-(start_i+1)]]):\n",
    "                valence = valence*N_SCALAR\n",
    "        return valence\n",
    "\n",
    "    def _punctuation_emphasis(self, sum_s, text):\n",
    "        # add emphasis from exclamation points and question marks\n",
    "        ep_amplifier = self._amplify_ep(text)\n",
    "        qm_amplifier = self._amplify_qm(text)\n",
    "        punct_emph_amplifier = ep_amplifier+qm_amplifier\n",
    "        return punct_emph_amplifier\n",
    "\n",
    "    def _amplify_ep(self, text):\n",
    "        # check for added emphasis resulting from exclamation points (up to 4 of them)\n",
    "        ep_count = text.count(\"!\")\n",
    "        if ep_count > 4:\n",
    "            ep_count = 4\n",
    "        # (empirically derived mean sentiment intensity rating increase for\n",
    "        # exclamation points)\n",
    "        ep_amplifier = ep_count*0.292\n",
    "        return ep_amplifier\n",
    "\n",
    "    def _amplify_qm(self, text):\n",
    "        # check for added emphasis resulting from question marks (2 or 3+)\n",
    "        qm_count = text.count(\"?\")\n",
    "        qm_amplifier = 0\n",
    "        if qm_count > 1:\n",
    "            if qm_count <= 3:\n",
    "                # (empirically derived mean sentiment intensity rating increase for\n",
    "                # question marks)\n",
    "                qm_amplifier = qm_count*0.18\n",
    "            else:\n",
    "                qm_amplifier = 0.96\n",
    "        return qm_amplifier\n",
    "\n",
    "    def _sift_sentiment_scores(self, sentiments):\n",
    "        # want separate positive versus negative sentiment scores\n",
    "        pos_sum = 0.0\n",
    "        neg_sum = 0.0\n",
    "        neu_count = 0\n",
    "        for sentiment_score in sentiments:\n",
    "            if sentiment_score > 0:\n",
    "                pos_sum += (float(sentiment_score) +1) # compensates for neutral words that are counted as 1\n",
    "            if sentiment_score < 0:\n",
    "                neg_sum += (float(sentiment_score) -1) # when used with math.fabs(), compensates for neutrals\n",
    "            if sentiment_score == 0:\n",
    "                neu_count += 1\n",
    "        return pos_sum, neg_sum, neu_count\n",
    "\n",
    "    def score_valence(self, sentiments, text):\n",
    "        if sentiments:\n",
    "            sum_s = float(sum(sentiments))\n",
    "            # compute and add emphasis from punctuation in text\n",
    "            punct_emph_amplifier = self._punctuation_emphasis(sum_s, text)\n",
    "            if sum_s > 0:\n",
    "                sum_s += punct_emph_amplifier\n",
    "            elif  sum_s < 0:\n",
    "                sum_s -= punct_emph_amplifier\n",
    "\n",
    "            compound = normalize(sum_s)\n",
    "            # discriminate between positive, negative and neutral sentiment scores\n",
    "            pos_sum, neg_sum, neu_count = self._sift_sentiment_scores(sentiments)\n",
    "\n",
    "            if pos_sum > math.fabs(neg_sum):\n",
    "                pos_sum += (punct_emph_amplifier)\n",
    "            elif pos_sum < math.fabs(neg_sum):\n",
    "                neg_sum -= (punct_emph_amplifier)\n",
    "\n",
    "            total = pos_sum + math.fabs(neg_sum) + neu_count\n",
    "            pos = math.fabs(pos_sum / total)\n",
    "            neg = math.fabs(neg_sum / total)\n",
    "            neu = math.fabs(neu_count / total)\n",
    "\n",
    "        else:\n",
    "            compound = 0.0\n",
    "            pos = 0.0\n",
    "            neg = 0.0\n",
    "            neu = 0.0\n",
    "\n",
    "        sentiment_dict = \\\n",
    "            {\"neg\" : round(neg, 3),\n",
    "             \"neu\" : round(neu, 3),\n",
    "             \"pos\" : round(pos, 3),\n",
    "             \"compound\" : round(compound, 4)}\n",
    "\n",
    "        return sentiment_dict\n",
    "    \n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    to_lang = 'en'\n",
    "    \n",
    "    list_files=[\"database_11_1.sqlite\",\"database_12_0.sqlite\",\"database_12_1.sqlite\",\"database_13_0.sqlite\",\"database_13_1.sqlite\",\"database_14_0.sqlite\",\"database_15_0.sqlite\",\"database_15_1.sqlite\",\"database_16_0.sqlite\",\"database_16_1.sqlite\",\"database_17_0.sqlite\",\"database_14_1.sqlite\"]\n",
    "\n",
    "    list_df=[]\n",
    "    \n",
    "    for file in list_files:\n",
    "        print(file)\n",
    "        #name = \"%d.csv\" % file\n",
    "        connection = sqlite3.connect(format(file))\n",
    "        df= pd.read_sql_query(\"SELECT * from data\", connection)\n",
    "        connection.close()\n",
    "        #Filter the data \n",
    "        #df_tweet=df_tweet.loc[df_tweet['lang']==\"fr\"]\n",
    "        \n",
    "    \n",
    "        for index,row in df.iterrows():               \n",
    "            text = row.text\n",
    "            from_lang = row.lang\n",
    "            paragraphSentiments=0.0 \n",
    "\n",
    "\n",
    "            from nltk import tokenize\n",
    "            sentence_list = tokenize.sent_tokenize(text)\n",
    "            length = len(sentence_list)\n",
    "\n",
    "\n",
    "            if from_lang != 'en':\n",
    "                for sentence in sentence_list:\n",
    "                    api_url = \"http://mymemory.translated.net/api/get?q={}&langpair={}|{}\".format(sentence, from_lang, to_lang)\n",
    "                    hdrs ={'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "                           'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "                           'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "                           'Accept-Encoding': 'none',\n",
    "                           'Accept-Language': 'en-US,en;q=0.8',\n",
    "                           'Connection': 'keep-alive'}\n",
    "                    response_json = requests.get(api_url, headers=hdrs).json()\n",
    "                    #response_json = simplejson.loads(response.text)\n",
    "                    translation = response_json[\"responseData\"][\"translatedText\"]\n",
    "                    translator_name = \"MemoryNet Translation Service\"\n",
    "                    if translation:\n",
    "                        vs=analyzer.polarity_scores(translation)\n",
    "                    else:\n",
    "                        length=length-1\n",
    "                    paragraphSentiments += vs[\"compound\"]\n",
    "                sentimentScore = str(round(paragraphSentiments/length, 4)) \n",
    "            if from_lang == 'en':\n",
    "                for sentence in sentence_list:\n",
    "                    vs = analyzer.polarity_scores(sentence)\n",
    "                    paragraphSentiments += vs[\"compound\"]\n",
    "                sentimentScore = str(round(paragraphSentiments/length, 4)) \n",
    "            \"\"\"\n",
    "            if from_lang =='fr':\n",
    "                for sentence in sentence_list:\n",
    "                    tb = Blobber(pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "                    blob = tb(sentence)\n",
    "                    x = blob.sentiment\n",
    "                    vs = x[0]\n",
    "                    paragraphSentiments += vs\n",
    "                sentimentScore = str(round(paragraphSentiments/length, 4))                            \n",
    "            \"\"\"\n",
    "            df.set_value(index,'score',sentimentScore)\n",
    "        df.to_csv(file + \".csv\")\n",
    "        list_df.append(df)\n",
    "   \n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df['day']==\"2017-04-25\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f517969f4c5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2924\u001b[0m         \u001b[0mwill\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mflot64\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2925\u001b[0m         \"\"\"\n\u001b[0;32m-> 2926\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2928\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mas_matrix\u001b[0;34m(self, columns)\u001b[0m\n\u001b[1;32m   2905\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2906\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2907\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2908\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mas_matrix\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m   3378\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3380\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_interleave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3406\u001b[0m             \u001b[0mrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3407\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3408\u001b[0m             \u001b[0mitemmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for index,row in df.iterrows():  \n",
    "    print df.values[index][22]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>location</th>\n",
       "      <th>mention_Arthaud</th>\n",
       "      <th>mention_Asselineau</th>\n",
       "      <th>mention_Cheminade</th>\n",
       "      <th>mention_Dupont-Aignan</th>\n",
       "      <th>mention_Fillon</th>\n",
       "      <th>mention_Hamon</th>\n",
       "      <th>mention_Lassalle</th>\n",
       "      <th>mention_Le Pen</th>\n",
       "      <th>...</th>\n",
       "      <th>mention_Poutou</th>\n",
       "      <th>quoted/retweeted full_text</th>\n",
       "      <th>quoted/retweeted user</th>\n",
       "      <th>quoted/retweeted?</th>\n",
       "      <th>text</th>\n",
       "      <th>timestampms</th>\n",
       "      <th>user</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>0</td>\n",
       "      <td>Diderot &amp; Alger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>François Fillon explique que les Etats-Unis on...</td>\n",
       "      <td>Macron 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>L'histoire que veut récrire  #fillon: les Etat...</td>\n",
       "      <td>1492388581209</td>\n",
       "      <td>Masnsen</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>1</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@J_Villumsen @JLMelenchon FILLON DÉGAGE ! #Fil...</td>\n",
       "      <td>1492388581726</td>\n",
       "      <td>Perfide Filon</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>@jpstar22 @Fillon_78 Déjà que j'étais sur a 50...</td>\n",
       "      <td>DESIRE COULIBALY</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @desirecoulibaly: @jpstar22 @Fillon_78 Déjà...</td>\n",
       "      <td>1492388582289</td>\n",
       "      <td>LEJEUNE</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>This looks familiar to you? Same tactics used ...</td>\n",
       "      <td>ALT🛂 Immigration</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @ALT_uscis: This looks familiar to you? Sam...</td>\n",
       "      <td>1492388582769</td>\n",
       "      <td>Brian Thornton</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>4</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Et voici la cartographie animée de l'opération...</td>\n",
       "      <td>Nicolas Vanderbiest</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @auroreberge: Jusqu'où ira cette fin de cam...</td>\n",
       "      <td>1492388582706</td>\n",
       "      <td>Chinaski</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@Ant1Adam Dans les faits, quoi de nouveau avec...</td>\n",
       "      <td>1492388583215</td>\n",
       "      <td>Léo</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@LCI https://t.co/o8TZW8TR4G Gagner 3€ en inve...</td>\n",
       "      <td>1492388583376</td>\n",
       "      <td>🔧 🔩🔧🎅:-)</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @Valeurs: Mohamed Saou : le scandale qui pe...</td>\n",
       "      <td>1492388583578</td>\n",
       "      <td>foldactu</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>und</th>\n",
       "      <td>8</td>\n",
       "      <td>Galway</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@Nomie92667707 https://t.co/YNEracOQzl</td>\n",
       "      <td>1492388584776</td>\n",
       "      <td>Kevin Higgins - poet</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9</td>\n",
       "      <td>Saint-Egrève | Saint-Eustache</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @Droitdanslemur1: Je suis proche des idées ...</td>\n",
       "      <td>1492388584930</td>\n",
       "      <td>Clément Chappet</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>10</td>\n",
       "      <td>Dixon Lake</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @PrisonPlanet: 500,000 (almost all anti-Le ...</td>\n",
       "      <td>1492388586434</td>\n",
       "      <td>y - Mike Cutler</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>11</td>\n",
       "      <td>LE ONE PIECE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @vraiLuneLune: Étonnamment c'est Fillon qui...</td>\n",
       "      <td>1492388586834</td>\n",
       "      <td>laeti</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Alors, euh, comment dire ? C'est moi qui ai pr...</td>\n",
       "      <td>Hugo Clément</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @hugoclement: Alors, euh, comment dire ? C'...</td>\n",
       "      <td>1492388586791</td>\n",
       "      <td>salut</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>13</td>\n",
       "      <td>Cartagena- España</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Mélenchon y El arenque de Bismarck https://t.c...</td>\n",
       "      <td>1492388587307</td>\n",
       "      <td>Eduardo Alarcon</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @Valeurs: Mohamed Saou : le scandale qui pe...</td>\n",
       "      <td>1492388583578</td>\n",
       "      <td>foldactu</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>15</td>\n",
       "      <td>Niall my treasure ♥</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @dimitriskad: T'as oublié MARINE, des racis...</td>\n",
       "      <td>1492388588472</td>\n",
       "      <td>Yacine 🌹</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>16</td>\n",
       "      <td>Toulouse, France</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @MilanPrados1: Jean-Luc Mélenchon à la prai...</td>\n",
       "      <td>1492388588716</td>\n",
       "      <td>Jean 🔻</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>17</td>\n",
       "      <td>Paris</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@Heaaaaal C'est ça ! Tout le monde dit \" tout ...</td>\n",
       "      <td>1492388589564</td>\n",
       "      <td>Poivrotte huppée</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>18</td>\n",
       "      <td>Bruxelles, Belgique</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @SanglierSympa: Pourquoi voulez-vous voter ...</td>\n",
       "      <td>1492388589600</td>\n",
       "      <td>Thami Mekouar</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @V_of_Europe: Marine Le Pen: Pope Francis E...</td>\n",
       "      <td>1492388590328</td>\n",
       "      <td>Jeff Cohen</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>20</td>\n",
       "      <td>Белгородский район, Россия</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Jean-Luc Mélenchon se dit prêt à \"discuter ave...</td>\n",
       "      <td>Le Lab</td>\n",
       "      <td>1</td>\n",
       "      <td>Maintenant il croit en Allah ?\\nDérapage maçon...</td>\n",
       "      <td>1492388590639</td>\n",
       "      <td>L'Albinos</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>und</th>\n",
       "      <td>21</td>\n",
       "      <td>Galway</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@ormich https://t.co/YNEracOQzl</td>\n",
       "      <td>1492388591244</td>\n",
       "      <td>Kevin Higgins - poet</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@laurent97178 @monde9 \\nIl dit quoi HAMON sur ...</td>\n",
       "      <td>1492388591796</td>\n",
       "      <td>Shoumy DENICE</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>23</td>\n",
       "      <td>Perpignan, France</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @vraiLuneLune: Étonnamment c'est Fillon qui...</td>\n",
       "      <td>1492388591935</td>\n",
       "      <td>Kurama</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>24</td>\n",
       "      <td>Auvergne, France</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Quand pour prouver que 70 000 c'est possible, ...</td>\n",
       "      <td>1492388592216</td>\n",
       "      <td>Olivier Bernasson</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @lemonde_pol: #Présidentielle2017 | Le Pen,...</td>\n",
       "      <td>1492388593047</td>\n",
       "      <td>Diop</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>26</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>#NousVoici ¡Aquí estamos!\\nSus palabras salen ...</td>\n",
       "      <td>Piedad Córdoba Ruiz</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @piedadcordoba: #NousVoici ¡Aquí estamos!\\n...</td>\n",
       "      <td>1492388593483</td>\n",
       "      <td>ana maria torres</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>27</td>\n",
       "      <td>Nice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @JIBE04: Avec des amis comme ça @FrancoisFi...</td>\n",
       "      <td>1492388593861</td>\n",
       "      <td>Seymour Glass</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>28</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@TheEconomist @KanchanGupta Looks like Macron ...</td>\n",
       "      <td>1492388593962</td>\n",
       "      <td>🕉gab.ai/Rbhrgvr🕉</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ro</th>\n",
       "      <td>29</td>\n",
       "      <td>Valhalla</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @Jowkeer: [Theorie Ryo Sensei] Fillon doit ...</td>\n",
       "      <td>1492388594095</td>\n",
       "      <td>Azarath</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>und</th>\n",
       "      <td>9268</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>#France Choose wisely -Choose #LePan  Paris #T...</td>\n",
       "      <td>BenGarrison Cartoons</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @NewCdnPMneeded: #lepen2017 https://t.co/AY...</td>\n",
       "      <td>1492731780521</td>\n",
       "      <td>AllHumansMatter</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9269</td>\n",
       "      <td>was shereenate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Pour ceux qui voteront Marine LE PEN: \\nN'OUBL...</td>\n",
       "      <td>•K L A I NY•🇨🇩🇹🇬</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @Keezybs: Pour ceux qui voteront Marine LE ...</td>\n",
       "      <td>1492731780752</td>\n",
       "      <td>solène</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9270</td>\n",
       "      <td>Paris</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @LabVince: Menteur sur la fusillade des #ch...</td>\n",
       "      <td>1492731781124</td>\n",
       "      <td>Pascal Manry</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>9271</td>\n",
       "      <td>Dallas, Texas</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Méprisable! Mélenchon, Le Pen, and Fillon are ...</td>\n",
       "      <td>Garry Kasparov</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @Kasparov63: Méprisable! Mélenchon, Le Pen,...</td>\n",
       "      <td>1492731781261</td>\n",
       "      <td>Greg Gaylor</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>9272</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @StefanMolyneux: Marine Le Pen: 'Mass Immig...</td>\n",
       "      <td>1492731781293</td>\n",
       "      <td>Chicago Cabbie</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9273</td>\n",
       "      <td>Lille, France</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @pascalriche: #ChampsElysées M.Le Pen et F....</td>\n",
       "      <td>1492731781570</td>\n",
       "      <td>PriscilliaMbemba</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9274</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@MLP_officiel Mdrr calme toi ma gueulle, la me...</td>\n",
       "      <td>1492731781427</td>\n",
       "      <td>Eniram</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9275</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Alors #Fillon, quand c'est que tu rend l'argen...</td>\n",
       "      <td>1492731781763</td>\n",
       "      <td>millet</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9276</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @BriceBlazy: Pourquoi #Fillon est le candid...</td>\n",
       "      <td>1492731781752</td>\n",
       "      <td>RPF Ile de France</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9277</td>\n",
       "      <td>Eure-et-Loir, Centre</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Fillon fait bondir avec ce sous-entendu sur la...</td>\n",
       "      <td>L'important</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @Limportant_fr: Fillon fait bondir avec ce ...</td>\n",
       "      <td>1492731781960</td>\n",
       "      <td>Gladia SOLARIA</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9278</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>marine le pen\\ngrosse pute de merde\\nvotez mel...</td>\n",
       "      <td>1492731782322</td>\n",
       "      <td>🔪🔪🔪</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>9279</td>\n",
       "      <td>London, England</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @Marine2017_EN: 🌎 RT for #Marine ! #Paris ...</td>\n",
       "      <td>1492731782315</td>\n",
       "      <td>Michael Payne</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9280</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @Paranoid_sO: Venez on va tous vivre ds les...</td>\n",
       "      <td>1492731782465</td>\n",
       "      <td>les Balkans Nient</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>9281</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@werbttrthanthis @AnthonyEinzig It is probably...</td>\n",
       "      <td>1492731782694</td>\n",
       "      <td>SharonT</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9282</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @lauhaim: Cet après-midi @EmmanuelMacron s'...</td>\n",
       "      <td>1492731782811</td>\n",
       "      <td>Margaret Dugas</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>9283</td>\n",
       "      <td>Edmonton, Alberta Canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @_Makada_: Radical Islamic terrorists just ...</td>\n",
       "      <td>1492731782903</td>\n",
       "      <td>C.T.</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>9284</td>\n",
       "      <td>Albertville, AL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @FiveRights: Paris, you can end all this cr...</td>\n",
       "      <td>1492731783023</td>\n",
       "      <td>NO PC BS</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>9285</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @TEN_GOP: Marine Le Pen: “They kill our chi...</td>\n",
       "      <td>1492731783272</td>\n",
       "      <td>Lake Deplorable</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9286</td>\n",
       "      <td>Seul</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @Siham_IIham: J'espère que Mélenchon passer...</td>\n",
       "      <td>1492731783395</td>\n",
       "      <td>O'Koro</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9287</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Pour ceux qui voteront Marine LE PEN: \\nN'OUBL...</td>\n",
       "      <td>•K L A I NY•🇨🇩🇹🇬</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @Keezybs: Pour ceux qui voteront Marine LE ...</td>\n",
       "      <td>1492731783456</td>\n",
       "      <td>NAÂMAN</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9288</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Quand soudain, François Fillon explique à Léa ...</td>\n",
       "      <td>BuzzFeed Politique</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @BuzzFeedFRpol: Quand soudain, François Fil...</td>\n",
       "      <td>1492731783646</td>\n",
       "      <td>📢 kaléidoscope 📢</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>9289</td>\n",
       "      <td>USA Gods country</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Marine Le Pen:\\n\"I don't want to say our youth...</td>\n",
       "      <td>Avanti Populists !</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @abermans: Marine Le Pen:\\n\"I don't want to...</td>\n",
       "      <td>1492731783960</td>\n",
       "      <td>Anthony M</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9290</td>\n",
       "      <td>Francophonie</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@BigKhulann @juliensalingue Je n'ai pas l'impr...</td>\n",
       "      <td>1492731783929</td>\n",
       "      <td>Louis Riel</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9291</td>\n",
       "      <td>Arcueil, France</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @ISLAMOO_92: J'SUIS SUR ENFETE C LE PEN ELL...</td>\n",
       "      <td>1492731784167</td>\n",
       "      <td>🤘🏽🉐</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9292</td>\n",
       "      <td>France,fille aînée de l’Eglise</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@PhilippePoutou Macron sort de ce corps !</td>\n",
       "      <td>1492731784473</td>\n",
       "      <td>Lily-Rose 🇫🇷 ７３２</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9293</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @UnBaton_: \"Madame Le Pen fusillade sur les...</td>\n",
       "      <td>1492731784746</td>\n",
       "      <td>Belinda</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9294</td>\n",
       "      <td>|||</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @MisapiDance: Avant de voter, n'oubliez pas...</td>\n",
       "      <td>1492731784742</td>\n",
       "      <td>-</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9295</td>\n",
       "      <td>Paris, Ile-de-France</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @bernardpivot1: \"Mon pied droit est jaloux ...</td>\n",
       "      <td>1492731784973</td>\n",
       "      <td>Groupe J.-P. Vernant</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9296</td>\n",
       "      <td>Antony</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @loicsignor: Contrairement à @FrancoisFillo...</td>\n",
       "      <td>1492731785022</td>\n",
       "      <td>Lucien .T 🇫🇷🇪🇺</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>9297</td>\n",
       "      <td>Caldwell,Id</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @Pamela_Moore13: After watching this video,...</td>\n",
       "      <td>1492731785119</td>\n",
       "      <td>Deplorable Gale</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1021989 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                        location  mention_Arthaud  \\\n",
       "lang                                                           \n",
       "fr        0                Diderot & Alger                 0   \n",
       "fr        1                   Paris, France                0   \n",
       "fr        2                            None                0   \n",
       "en        3                            None                0   \n",
       "fr        4                   Paris, France                0   \n",
       "fr        5                            None                0   \n",
       "fr        6                            None                0   \n",
       "fr        7                            None                0   \n",
       "und       8                          Galway                0   \n",
       "fr        9   Saint-Egrève | Saint-Eustache                0   \n",
       "en       10                      Dixon Lake                0   \n",
       "fr       11                    LE ONE PIECE                0   \n",
       "fr       12                            None                0   \n",
       "fr       13               Cartagena- España                0   \n",
       "fr       14                            None                0   \n",
       "fr       15             Niall my treasure ♥                0   \n",
       "fr       16                Toulouse, France                0   \n",
       "fr       17                           Paris                0   \n",
       "fr       18             Bruxelles, Belgique                0   \n",
       "en       19                            None                0   \n",
       "fr       20      Белгородский район, Россия                0   \n",
       "und      21                          Galway                0   \n",
       "fr       22                            None                0   \n",
       "fr       23               Perpignan, France                0   \n",
       "fr       24                Auvergne, France                0   \n",
       "fr       25                            None                0   \n",
       "es       26                            None                0   \n",
       "fr       27                            Nice                0   \n",
       "in       28                       Bangalore                0   \n",
       "ro       29                        Valhalla                0   \n",
       "...     ...                             ...              ...   \n",
       "und    9268                            None                0   \n",
       "fr     9269                  was shereenate                0   \n",
       "fr     9270                           Paris                0   \n",
       "en     9271                   Dallas, Texas                0   \n",
       "en     9272                         Chicago                0   \n",
       "fr     9273                   Lille, France                0   \n",
       "fr     9274                            None                0   \n",
       "fr     9275                            None                0   \n",
       "fr     9276                   Paris, France                0   \n",
       "fr     9277            Eure-et-Loir, Centre                0   \n",
       "fr     9278                            None                0   \n",
       "en     9279                 London, England                0   \n",
       "fr     9280                            None                0   \n",
       "en     9281                            None                0   \n",
       "fr     9282                            None                0   \n",
       "en     9283        Edmonton, Alberta Canada                0   \n",
       "en     9284                 Albertville, AL                0   \n",
       "en     9285                            None                0   \n",
       "fr     9286                            Seul                0   \n",
       "fr     9287                            None                0   \n",
       "fr     9288                          France                0   \n",
       "en     9289                USA Gods country                0   \n",
       "fr     9290                    Francophonie                0   \n",
       "fr     9291                 Arcueil, France                0   \n",
       "fr     9292  France,fille aînée de l’Eglise                0   \n",
       "fr     9293                            None                0   \n",
       "fr     9294                            |||                 0   \n",
       "fr     9295            Paris, Ile-de-France                0   \n",
       "fr     9296                          Antony                0   \n",
       "en     9297                     Caldwell,Id                0   \n",
       "\n",
       "      mention_Asselineau  mention_Cheminade  mention_Dupont-Aignan  \\\n",
       "lang                                                                 \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "en                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "und                    0                  0                      0   \n",
       "fr                     0                  0                      1   \n",
       "en                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "en                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "und                    0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "es                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "in                     0                  0                      0   \n",
       "ro                     0                  0                      0   \n",
       "...                  ...                ...                    ...   \n",
       "und                    0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "en                     0                  0                      0   \n",
       "en                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "en                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "en                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "en                     0                  0                      0   \n",
       "en                     0                  0                      0   \n",
       "en                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "en                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "fr                     0                  0                      0   \n",
       "en                     0                  0                      0   \n",
       "\n",
       "      mention_Fillon  mention_Hamon  mention_Lassalle  mention_Le Pen  ...   \\\n",
       "lang                                                                   ...    \n",
       "fr                 1              0                 0               0  ...    \n",
       "fr                 1              0                 0               0  ...    \n",
       "fr                 1              0                 0               0  ...    \n",
       "en                 0              0                 0               1  ...    \n",
       "fr                 1              0                 0               0  ...    \n",
       "fr                 0              0                 0               0  ...    \n",
       "fr                 0              0                 0               0  ...    \n",
       "fr                 0              0                 0               0  ...    \n",
       "und                0              0                 0               0  ...    \n",
       "fr                 1              0                 0               0  ...    \n",
       "en                 0              0                 0               1  ...    \n",
       "fr                 1              0                 0               0  ...    \n",
       "fr                 1              0                 0               0  ...    \n",
       "fr                 0              0                 0               0  ...    \n",
       "fr                 0              0                 0               0  ...    \n",
       "fr                 0              0                 0               0  ...    \n",
       "fr                 0              0                 0               0  ...    \n",
       "fr                 0              0                 0               0  ...    \n",
       "fr                 0              0                 0               0  ...    \n",
       "en                 0              0                 0               1  ...    \n",
       "fr                 0              0                 0               0  ...    \n",
       "und                0              0                 0               0  ...    \n",
       "fr                 0              1                 0               0  ...    \n",
       "fr                 1              0                 0               0  ...    \n",
       "fr                 0              0                 0               0  ...    \n",
       "fr                 1              0                 0               1  ...    \n",
       "es                 0              0                 0               0  ...    \n",
       "fr                 1              0                 0               0  ...    \n",
       "in                 0              0                 0               0  ...    \n",
       "ro                 1              0                 0               0  ...    \n",
       "...              ...            ...               ...             ...  ...    \n",
       "und                0              0                 0               1  ...    \n",
       "fr                 0              0                 0               1  ...    \n",
       "fr                 1              0                 0               0  ...    \n",
       "en                 1              0                 0               1  ...    \n",
       "en                 0              0                 0               1  ...    \n",
       "fr                 1              0                 0               1  ...    \n",
       "fr                 0              0                 0               1  ...    \n",
       "fr                 1              0                 0               0  ...    \n",
       "fr                 1              0                 0               0  ...    \n",
       "fr                 1              0                 0               0  ...    \n",
       "fr                 0              0                 0               1  ...    \n",
       "en                 0              0                 0               1  ...    \n",
       "fr                 0              0                 0               1  ...    \n",
       "en                 0              0                 0               1  ...    \n",
       "fr                 0              0                 0               0  ...    \n",
       "en                 0              0                 0               1  ...    \n",
       "en                 0              0                 0               1  ...    \n",
       "en                 0              0                 0               1  ...    \n",
       "fr                 0              0                 0               0  ...    \n",
       "fr                 0              0                 0               1  ...    \n",
       "fr                 1              0                 0               0  ...    \n",
       "en                 0              0                 0               1  ...    \n",
       "fr                 0              0                 0               0  ...    \n",
       "fr                 0              0                 0               1  ...    \n",
       "fr                 0              0                 0               0  ...    \n",
       "fr                 0              0                 0               1  ...    \n",
       "fr                 1              0                 0               0  ...    \n",
       "fr                 0              0                 0               0  ...    \n",
       "fr                 1              0                 0               1  ...    \n",
       "en                 0              0                 0               1  ...    \n",
       "\n",
       "      mention_Poutou                         quoted/retweeted full_text  \\\n",
       "lang                                                                      \n",
       "fr                 0  François Fillon explique que les Etats-Unis on...   \n",
       "fr                 0                                               None   \n",
       "fr                 0  @jpstar22 @Fillon_78 Déjà que j'étais sur a 50...   \n",
       "en                 0  This looks familiar to you? Same tactics used ...   \n",
       "fr                 0  Et voici la cartographie animée de l'opération...   \n",
       "fr                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "und                0                                               None   \n",
       "fr                 0                                               None   \n",
       "en                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 0  Alors, euh, comment dire ? C'est moi qui ai pr...   \n",
       "fr                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "en                 0                                               None   \n",
       "fr                 0  Jean-Luc Mélenchon se dit prêt à \"discuter ave...   \n",
       "und                0                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "es                 0  #NousVoici ¡Aquí estamos!\\nSus palabras salen ...   \n",
       "fr                 0                                               None   \n",
       "in                 0                                               None   \n",
       "ro                 0                                               None   \n",
       "...              ...                                                ...   \n",
       "und                0  #France Choose wisely -Choose #LePan  Paris #T...   \n",
       "fr                 0  Pour ceux qui voteront Marine LE PEN: \\nN'OUBL...   \n",
       "fr                 0                                               None   \n",
       "en                 0  Méprisable! Mélenchon, Le Pen, and Fillon are ...   \n",
       "en                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 0  Fillon fait bondir avec ce sous-entendu sur la...   \n",
       "fr                 0                                               None   \n",
       "en                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "en                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "en                 0                                               None   \n",
       "en                 0                                               None   \n",
       "en                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 0  Pour ceux qui voteront Marine LE PEN: \\nN'OUBL...   \n",
       "fr                 0  Quand soudain, François Fillon explique à Léa ...   \n",
       "en                 0  Marine Le Pen:\\n\"I don't want to say our youth...   \n",
       "fr                 1                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 1                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "fr                 0                                               None   \n",
       "en                 0                                               None   \n",
       "\n",
       "      quoted/retweeted user quoted/retweeted?  \\\n",
       "lang                                            \n",
       "fr              Macron 2017                 1   \n",
       "fr                     None                 0   \n",
       "fr         DESIRE COULIBALY                 1   \n",
       "en        ALT🛂 Immigration                 1   \n",
       "fr      Nicolas Vanderbiest                 1   \n",
       "fr                     None                 0   \n",
       "fr                     None                 0   \n",
       "fr                     None                 1   \n",
       "und                    None                 0   \n",
       "fr                     None                 1   \n",
       "en                     None                 1   \n",
       "fr                     None                 1   \n",
       "fr             Hugo Clément                 1   \n",
       "fr                     None                 0   \n",
       "fr                     None                 1   \n",
       "fr                     None                 1   \n",
       "fr                     None                 1   \n",
       "fr                     None                 0   \n",
       "fr                     None                 1   \n",
       "en                     None                 1   \n",
       "fr                   Le Lab                 1   \n",
       "und                    None                 0   \n",
       "fr                     None                 0   \n",
       "fr                     None                 1   \n",
       "fr                     None                 1   \n",
       "fr                     None                 1   \n",
       "es      Piedad Córdoba Ruiz                 1   \n",
       "fr                     None                 1   \n",
       "in                     None                 0   \n",
       "ro                     None                 1   \n",
       "...                     ...               ...   \n",
       "und    BenGarrison Cartoons                 1   \n",
       "fr     •K L A I NY•🇨🇩🇹🇬                 1   \n",
       "fr                     None                 1   \n",
       "en           Garry Kasparov                 1   \n",
       "en                     None                 1   \n",
       "fr                     None                 1   \n",
       "fr                     None                 0   \n",
       "fr                     None                 0   \n",
       "fr                     None                 1   \n",
       "fr              L'important                 1   \n",
       "fr                     None                 0   \n",
       "en                     None                 1   \n",
       "fr                     None                 1   \n",
       "en                     None                 0   \n",
       "fr                     None                 1   \n",
       "en                     None                 1   \n",
       "en                     None                 1   \n",
       "en                     None                 1   \n",
       "fr                     None                 1   \n",
       "fr     •K L A I NY•🇨🇩🇹🇬                 1   \n",
       "fr       BuzzFeed Politique                 1   \n",
       "en       Avanti Populists !                 1   \n",
       "fr                     None                 0   \n",
       "fr                     None                 1   \n",
       "fr                     None                 0   \n",
       "fr                     None                 1   \n",
       "fr                     None                 1   \n",
       "fr                     None                 1   \n",
       "fr                     None                 1   \n",
       "en                     None                 1   \n",
       "\n",
       "                                                   text    timestampms  \\\n",
       "lang                                                                     \n",
       "fr    L'histoire que veut récrire  #fillon: les Etat...  1492388581209   \n",
       "fr    @J_Villumsen @JLMelenchon FILLON DÉGAGE ! #Fil...  1492388581726   \n",
       "fr    RT @desirecoulibaly: @jpstar22 @Fillon_78 Déjà...  1492388582289   \n",
       "en    RT @ALT_uscis: This looks familiar to you? Sam...  1492388582769   \n",
       "fr    RT @auroreberge: Jusqu'où ira cette fin de cam...  1492388582706   \n",
       "fr    @Ant1Adam Dans les faits, quoi de nouveau avec...  1492388583215   \n",
       "fr    @LCI https://t.co/o8TZW8TR4G Gagner 3€ en inve...  1492388583376   \n",
       "fr    RT @Valeurs: Mohamed Saou : le scandale qui pe...  1492388583578   \n",
       "und              @Nomie92667707 https://t.co/YNEracOQzl  1492388584776   \n",
       "fr    RT @Droitdanslemur1: Je suis proche des idées ...  1492388584930   \n",
       "en    RT @PrisonPlanet: 500,000 (almost all anti-Le ...  1492388586434   \n",
       "fr    RT @vraiLuneLune: Étonnamment c'est Fillon qui...  1492388586834   \n",
       "fr    RT @hugoclement: Alors, euh, comment dire ? C'...  1492388586791   \n",
       "fr    Mélenchon y El arenque de Bismarck https://t.c...  1492388587307   \n",
       "fr    RT @Valeurs: Mohamed Saou : le scandale qui pe...  1492388583578   \n",
       "fr    RT @dimitriskad: T'as oublié MARINE, des racis...  1492388588472   \n",
       "fr    RT @MilanPrados1: Jean-Luc Mélenchon à la prai...  1492388588716   \n",
       "fr    @Heaaaaal C'est ça ! Tout le monde dit \" tout ...  1492388589564   \n",
       "fr    RT @SanglierSympa: Pourquoi voulez-vous voter ...  1492388589600   \n",
       "en    RT @V_of_Europe: Marine Le Pen: Pope Francis E...  1492388590328   \n",
       "fr    Maintenant il croit en Allah ?\\nDérapage maçon...  1492388590639   \n",
       "und                     @ormich https://t.co/YNEracOQzl  1492388591244   \n",
       "fr    @laurent97178 @monde9 \\nIl dit quoi HAMON sur ...  1492388591796   \n",
       "fr    RT @vraiLuneLune: Étonnamment c'est Fillon qui...  1492388591935   \n",
       "fr    Quand pour prouver que 70 000 c'est possible, ...  1492388592216   \n",
       "fr    RT @lemonde_pol: #Présidentielle2017 | Le Pen,...  1492388593047   \n",
       "es    RT @piedadcordoba: #NousVoici ¡Aquí estamos!\\n...  1492388593483   \n",
       "fr    RT @JIBE04: Avec des amis comme ça @FrancoisFi...  1492388593861   \n",
       "in    @TheEconomist @KanchanGupta Looks like Macron ...  1492388593962   \n",
       "ro    RT @Jowkeer: [Theorie Ryo Sensei] Fillon doit ...  1492388594095   \n",
       "...                                                 ...            ...   \n",
       "und   RT @NewCdnPMneeded: #lepen2017 https://t.co/AY...  1492731780521   \n",
       "fr    RT @Keezybs: Pour ceux qui voteront Marine LE ...  1492731780752   \n",
       "fr    RT @LabVince: Menteur sur la fusillade des #ch...  1492731781124   \n",
       "en    RT @Kasparov63: Méprisable! Mélenchon, Le Pen,...  1492731781261   \n",
       "en    RT @StefanMolyneux: Marine Le Pen: 'Mass Immig...  1492731781293   \n",
       "fr    RT @pascalriche: #ChampsElysées M.Le Pen et F....  1492731781570   \n",
       "fr    @MLP_officiel Mdrr calme toi ma gueulle, la me...  1492731781427   \n",
       "fr    Alors #Fillon, quand c'est que tu rend l'argen...  1492731781763   \n",
       "fr    RT @BriceBlazy: Pourquoi #Fillon est le candid...  1492731781752   \n",
       "fr    RT @Limportant_fr: Fillon fait bondir avec ce ...  1492731781960   \n",
       "fr    marine le pen\\ngrosse pute de merde\\nvotez mel...  1492731782322   \n",
       "en    RT @Marine2017_EN: 🌎 RT for #Marine ! #Paris ...  1492731782315   \n",
       "fr    RT @Paranoid_sO: Venez on va tous vivre ds les...  1492731782465   \n",
       "en    @werbttrthanthis @AnthonyEinzig It is probably...  1492731782694   \n",
       "fr    RT @lauhaim: Cet après-midi @EmmanuelMacron s'...  1492731782811   \n",
       "en    RT @_Makada_: Radical Islamic terrorists just ...  1492731782903   \n",
       "en    RT @FiveRights: Paris, you can end all this cr...  1492731783023   \n",
       "en    RT @TEN_GOP: Marine Le Pen: “They kill our chi...  1492731783272   \n",
       "fr    RT @Siham_IIham: J'espère que Mélenchon passer...  1492731783395   \n",
       "fr    RT @Keezybs: Pour ceux qui voteront Marine LE ...  1492731783456   \n",
       "fr    RT @BuzzFeedFRpol: Quand soudain, François Fil...  1492731783646   \n",
       "en    RT @abermans: Marine Le Pen:\\n\"I don't want to...  1492731783960   \n",
       "fr    @BigKhulann @juliensalingue Je n'ai pas l'impr...  1492731783929   \n",
       "fr    RT @ISLAMOO_92: J'SUIS SUR ENFETE C LE PEN ELL...  1492731784167   \n",
       "fr            @PhilippePoutou Macron sort de ce corps !  1492731784473   \n",
       "fr    RT @UnBaton_: \"Madame Le Pen fusillade sur les...  1492731784746   \n",
       "fr    RT @MisapiDance: Avant de voter, n'oubliez pas...  1492731784742   \n",
       "fr    RT @bernardpivot1: \"Mon pied droit est jaloux ...  1492731784973   \n",
       "fr    RT @loicsignor: Contrairement à @FrancoisFillo...  1492731785022   \n",
       "en    RT @Pamela_Moore13: After watching this video,...  1492731785119   \n",
       "\n",
       "                      user         day hour score  \n",
       "lang                                               \n",
       "fr                 Masnsen  2017-04-17   00  None  \n",
       "fr           Perfide Filon  2017-04-17   00  None  \n",
       "fr                 LEJEUNE  2017-04-17   00  None  \n",
       "en          Brian Thornton  2017-04-17   00  None  \n",
       "fr                Chinaski  2017-04-17   00  None  \n",
       "fr                     Léo  2017-04-17   00  None  \n",
       "fr            🔧 🔩🔧🎅:-)  2017-04-17   00  None  \n",
       "fr                foldactu  2017-04-17   00  None  \n",
       "und   Kevin Higgins - poet  2017-04-17   00  None  \n",
       "fr         Clément Chappet  2017-04-17   00  None  \n",
       "en         y - Mike Cutler  2017-04-17   00  None  \n",
       "fr                   laeti  2017-04-17   00  None  \n",
       "fr                   salut  2017-04-17   00  None  \n",
       "fr         Eduardo Alarcon  2017-04-17   00  None  \n",
       "fr                foldactu  2017-04-17   00  None  \n",
       "fr               Yacine 🌹  2017-04-17   00  None  \n",
       "fr                 Jean 🔻  2017-04-17   00  None  \n",
       "fr        Poivrotte huppée  2017-04-17   00  None  \n",
       "fr           Thami Mekouar  2017-04-17   00  None  \n",
       "en              Jeff Cohen  2017-04-17   00  None  \n",
       "fr               L'Albinos  2017-04-17   00  None  \n",
       "und   Kevin Higgins - poet  2017-04-17   00  None  \n",
       "fr           Shoumy DENICE  2017-04-17   00  None  \n",
       "fr                  Kurama  2017-04-17   00  None  \n",
       "fr       Olivier Bernasson  2017-04-17   00  None  \n",
       "fr                    Diop  2017-04-17   00  None  \n",
       "es        ana maria torres  2017-04-17   00  None  \n",
       "fr           Seymour Glass  2017-04-17   00  None  \n",
       "in      🕉gab.ai/Rbhrgvr🕉  2017-04-17   00  None  \n",
       "ro                 Azarath  2017-04-17   00  None  \n",
       "...                    ...         ...  ...   ...  \n",
       "und        AllHumansMatter  2017-04-20   23  None  \n",
       "fr                  solène  2017-04-20   23  None  \n",
       "fr            Pascal Manry  2017-04-20   23  None  \n",
       "en             Greg Gaylor  2017-04-20   23  None  \n",
       "en          Chicago Cabbie  2017-04-20   23  None  \n",
       "fr        PriscilliaMbemba  2017-04-20   23  None  \n",
       "fr                  Eniram  2017-04-20   23  None  \n",
       "fr                  millet  2017-04-20   23  None  \n",
       "fr       RPF Ile de France  2017-04-20   23  None  \n",
       "fr          Gladia SOLARIA  2017-04-20   23  None  \n",
       "fr                  🔪🔪🔪  2017-04-20   23  None  \n",
       "en           Michael Payne  2017-04-20   23  None  \n",
       "fr       les Balkans Nient  2017-04-20   23  None  \n",
       "en                 SharonT  2017-04-20   23  None  \n",
       "fr          Margaret Dugas  2017-04-20   23  None  \n",
       "en                    C.T.  2017-04-20   23  None  \n",
       "en                NO PC BS  2017-04-20   23  None  \n",
       "en         Lake Deplorable  2017-04-20   23  None  \n",
       "fr                  O'Koro  2017-04-20   23  None  \n",
       "fr                  NAÂMAN  2017-04-20   23  None  \n",
       "fr      📢 kaléidoscope 📢  2017-04-20   23  None  \n",
       "en               Anthony M  2017-04-20   23  None  \n",
       "fr              Louis Riel  2017-04-20   23  None  \n",
       "fr                  🤘🏽🉐  2017-04-20   23  None  \n",
       "fr      Lily-Rose 🇫🇷 ７３２  2017-04-20   23  None  \n",
       "fr                 Belinda  2017-04-20   23  None  \n",
       "fr                       -  2017-04-20   23  None  \n",
       "fr    Groupe J.-P. Vernant  2017-04-20   23  None  \n",
       "fr      Lucien .T 🇫🇷🇪🇺  2017-04-20   23  None  \n",
       "en         Deplorable Gale  2017-04-20   23  None  \n",
       "\n",
       "[1021989 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Data management libraries\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "connection = sqlite3.connect(\"database_16_0.sqlite\")\n",
    "c = connection.cursor()\n",
    "df = pd.read_sql_query(\"SELECT * from data\", connection)\n",
    "connection.close()\n",
    "\n",
    "df.set_index('lang')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "import sys  \n",
    "\n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "text=\"Quelle belle matinée\"\n",
    "tb = Blobber(pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "blob1 = tb(text)\n",
    "\n",
    "x=blob1.sentiment\n",
    "print x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-12effad7543e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mvs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-9ad40c0f4e7b>\u001b[0m in \u001b[0;36mpolarity_scores\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mvalence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \"\"\"\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0msentitext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentiText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;31m#text, words_and_emoticons, is_cap_diff = self.preprocess(text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-9ad40c0f4e7b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords_and_emoticons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_words_and_emoticons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "if translation:\n",
    "    vs=analyzer.polarity_scores(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
